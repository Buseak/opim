# -*- coding: utf-8 -*-
"""imdb.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uEA9XV6hMErCrFNKOMsoD0BI3Y2H7vro
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

IMDB = pd.read_csv('/content/drive/My Drive/opim/IMDB.csv')

IMDB.head()

movies = pd.read_csv('/content/drive/My Drive/opim/movies.csv', encoding='latin')

movies.head()

"""# Descriptive Statistics about IMDB Dataset"""

#Number of positive and negative reviews

positive = 0
negative = 0
len_IMDB=len(IMDB)

for i in range(len(IMDB)):
    if IMDB.iloc[i]['sentiment']=='positive':
      positive +=1
    else:
      negative +=1  

print(positive, negative, len_IMDB)

IMDB['splitted_review']=IMDB['review'].str.split(' ')

IMDB.head()

review_length=[]

for i in range(len(IMDB)):
  review_length.append(len(IMDB.iloc[i]['splitted_review']))

max(review_length)

from nltk import sent_tokenize
from nltk import word_tokenize
import nltk
from sklearn.feature_extraction.text import CountVectorizer
nltk.download('punkt')

IMDB['review_sentence']=IMDB['review'].apply(sent_tokenize)

IMDB.head()

review_length_sent=[]

for i in range(len(IMDB)):
  review_length_sent.append(len(IMDB.iloc[i]['review_sentence']))

import matplotlib.pyplot as plt

IMDB['review_lenght']=review_length_sent

import seaborn as sns
from scipy import stats
import matplotlib.pyplot as plt

IMDB.isna().sum() #NO NaN VALUE

fig = sns.distplot(IMDB['review_lenght'], norm_hist=True)

IMDB['sentiment'].value_counts().head(20).plot.bar()

dimensions = (35, 8)
fig, ax = plt.subplots(figsize=dimensions)
sns.set()
sns.boxplot(ax=ax, x='review_lenght',y='sentiment', data=IMDB, width=0.3)

"""Outlier Elimination"""

IMDB = IMDB[IMDB.review_lenght<25]

IMDB.head()

#Descriptive statistics after outlier elimination

#Number of positive and negative reviews

positive = 0
negative = 0
len_IMDB=len(IMDB)

for i in range(len(IMDB)):
    if IMDB.iloc[i]['sentiment']=='positive':
      positive +=1
    else:
      negative +=1  

print(positive, negative, len_IMDB)

from statistics import mean

mean(review_length_sent)

fig = sns.distplot(IMDB['review_lenght'], norm_hist=True)

IMDB['sentiment'].value_counts().head(20).plot.bar()

dimensions = (35, 8)
fig, ax = plt.subplots(figsize=dimensions)
sns.set()
sns.boxplot(ax=ax, x='review_lenght',y='sentiment', data=IMDB, width=0.3)

"""positive:right-skewd, negative:symmetric

# Data Preprocessing

1)positive :1, negative:0 (Turning categorical to numerical)
2)stopword removal, saçma işaretleri at
"""

#Converting categorical data to numerical by Mapping positives to 0 , negatives to 1

map = {'positive':0,'negative':1}
IMDB['sentiment'] = IMDB['sentiment'].replace(map)

IMDB.head()

IMDB['review']=IMDB['review'].str.lower()

from bs4 import BeautifulSoup
import re,string,unicodedata

#Removing the noisy text
def clean(text):
    soup = BeautifulSoup(text, "html.parser")
    text=soup.get_text()
    text = re.sub('\[[^]]*\]', '', text)
    pattern=r'[^a-zA-z0-9\s]'
    text=re.sub(pattern,'',text)
    return text
    

IMDB['review']=IMDB['review'].apply(clean)

from nltk.corpus import stopwords
nltk.download('stopwords')
from nltk.tokenize import word_tokenize

"""Train, Validation, Test Splitting"""

from sklearn.model_selection import train_test_split

train, test = train_test_split(IMDB, test_size=0.2)


test, val = train_test_split(test, test_size=0.5)

train.shape

IMDB['review']

from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer

vectorizer= TfidfVectorizer(stop_words='english', max_features=1000) #removing stopwords
vectorizer.fit(train['review']) #lowercasing tokens automatically

vectorizer.fit_transform(train['review'])

from sklearn.naive_bayes import GaussianNB, MultinomialNB

classifier = GaussianNB()
classifier.fit(vectorizer.transform(train['review']).toarray(), train['sentiment'])

from sklearn.metrics import classification_report, accuracy_score

predicted_label = classifier.predict(vectorizer.transform(val['review']).toarray())
print(accuracy_score(val['sentiment'], predicted_label))

from sklearn.linear_model import LogisticRegression

vectorizer= TfidfVectorizer(stop_words='english', max_features=1000) #removing stopwords
vectorizer.fit(train['review']) #lowercasing tokens automatically

lr_classifier=LogisticRegression()
lr_classifier.fit(vectorizer.transform(train['review']).toarray(), train['sentiment'])

predicted_label_lr = lr_classifier.predict(vectorizer.transform(val['review']).toarray())
print(accuracy_score(val['sentiment'], predicted_label_lr))

"""# Random Forest"""

from sklearn.ensemble import RandomForestClassifier

X_train=vectorizer.transform(train['review']).toarray()
X_valid=vectorizer.transform(val['review']).toarray()

classifier = RandomForestClassifier()#100 tree
classifier.fit(X_train, train['sentiment'])

Y_pred=classifier.predict(X_valid)

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

print(confusion_matrix(val['sentiment'],Y_pred))
print(classification_report(val['sentiment'],Y_pred))
print(accuracy_score(val['sentiment'],Y_pred))

"""# Movies dataset"""

movies.head()

movies.isna().sum() #NO NaN VALUE

movies['rating'].value_counts()

dimensions = (35, 8)
fig, ax = plt.subplots(figsize=dimensions)
sns.set()
sns.boxplot(ax=ax, x='score',y='votes', data=movies, width=0.3)

movies['score'].value_counts().head(20).plot.bar()

movies['company'].value_counts().head(20).plot.bar()

movies['country'].value_counts().head(20).plot.bar()

movies.head()

movies['genre'].value_counts().head(20).plot.bar()

for i in range(len(movies)):
  if movies.score.iloc[i]>=1 and movies.score.iloc[i]<2:
    movies.score.iloc[i]=1
  elif movies.score.iloc[i]>=2 and movies.score.iloc[i]<3:
    movies.score.iloc[i]=2
  elif movies.score.iloc[i]>=3 and movies.score.iloc[i]<4:
    movies.score.iloc[i]=3
  elif movies.score.iloc[i]>=4 and movies.score.iloc[i]<5:
    movies.score.iloc[i]=4
  elif movies.score.iloc[i]>=5 and movies.score.iloc[i]<6:
    movies.score.iloc[i]=5
  elif movies.score.iloc[i]>=6 and movies.score.iloc[i]<7:
    movies.score.iloc[i]=6
  elif movies.score.iloc[i]>=7 and movies.score.iloc[i]<8:
    movies.score.iloc[i]=7
  elif movies.score.iloc[i]>=8 and movies.score.iloc[i]<9:
    movies.score.iloc[i]=8
  elif movies.score.iloc[i]>=9 and movies.score.iloc[i]<10:
    movies.score.iloc[i]=9

plt.scatter(movies.score, movies.genre)

movies['score'].value_counts().head(20).plot.bar()

dimensions = (35, 8)
fig, ax = plt.subplots(figsize=dimensions)
sns.set()
sns.boxplot(ax=ax, x='score',y='votes', data=movies, width=0.3)

dimensions = (35, 8)
fig, ax = plt.subplots(figsize=dimensions)
sns.set()
sns.boxplot(ax=ax, x='score',y='budget', data=movies, width=0.3)

dimensions = (35, 8)
fig, ax = plt.subplots(figsize=dimensions)
sns.set()
sns.boxplot(ax=ax, x='genre',y='score', data=movies)

labels= movies['genre'].astype('category').cat.categories.to_list()
replace_map= {'genre' : {k: v for k,v in zip(labels,list(range(1,len(labels)+1)))}}
movies.replace(replace_map, inplace=True)
print(replace_map)

labels= movies['country'].astype('category').cat.categories.to_list()
replace_map= {'country' : {k: v for k,v in zip(labels,list(range(1,len(labels)+1)))}}
movies.replace(replace_map, inplace=True)
print(replace_map)

movies.head()

len(movies.company.unique())

movies.runtime.value_counts()

dimensions = (35, 8)
fig, ax = plt.subplots(figsize=dimensions)
sns.set()
sns.boxplot(ax=ax, x='score',y='runtime', data=movies)

movies = movies.drop(['company',
                      'director',
                      'name',
                      'released',
                      'star',
                      'writer',
                      'rating',
                      'year'
                      ],axis='columns')

"""# kNN"""

train, test = train_test_split(movies, test_size=0.2)

train.shape

test.shape

Y_train=train['score']

Y_train

X_train=train.drop(['score'],axis='columns' )

X_train.head()

Y_test=test['score']

X_test=test.drop(['score'],axis='columns' )

X_test.head()

knn=KNeighborsClassifier()
knn.fit(X_train, Y_train)

from sklearn.metrics import mean_squared_error

predicted_score=knn.predict(X_test)
print(accuracy_score(Y_test, predicted_score))

rms_knn = mean_squared_error(Y_test, predicted_score, squared=False)
rms_knn

from sklearn.ensemble import RandomForestRegressor

rf=RandomForestRegressor()

rf.fit(X_train, Y_train)

pred_score_rf=rf.predict(X_test)

rms = mean_squared_error(Y_test, pred_score_rf, squared=False)
rms

